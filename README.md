# Data Engineering project:Wikipedia Extraction and Database Integrtion

## project overview
This project focuses on extracting data from Wikipedia, cleaning it, and storing it in structured formats (CSV and JSON). The data is then loaded into two popular relational database management systems: PostgreSQL and MySQL. The primary goal is to gather information on the list of top universities, clean and process the data, and integrate it into relational databases for further analysis and querying.

## prerequisites
Before running this project, ensure the following dependencies are installed:

- **Python 3.7+**
**Libraries**:
1. **Requests**: For making HTTP requests to Wikipedia.
2. **Beautifulsoup4**: For scraping and parsing the HTML data.
3. **Pandas**: For cleaning, processing, and exporting data into CSV and JSON.
4. **Psycopg2**: PostgreSQL adapter for Python.
5. **Mysql-connector-python**: MySQL connector for Python.
6. **Sqlalchemy**: ORM to interact with PostgreSQL/MySQL databases.


